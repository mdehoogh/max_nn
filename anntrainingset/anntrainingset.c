/* anntrainingset.c */

#ifndef __LP64__
#define __LP64__ 1
#endif

#include "ext.h"
#include "ext_obex.h"

// we can create a structure to contain the pointers to the next set element and to the input/outputs
typedef struct anntrainingsetexample {
	double *inputs;
	double *outputs;
	struct anntrainingsetexample *next; // the pointer to the next example
} t_anntrainingsetexample;

// START structure definition
typedef struct anntrainingset {
	t_object a_ob;
	// we have a maximum of 5 arguments:
	long a_INPUTS; // number of inputs
	long a_OUTPUTS; // number of outputs
	long a_BATCHSIZE; // the number of inputs that constitute one epoch (0 means batch learning, 1 online learning)
	long a_ITERATIONS; // the maximum number of iterations in automatic training!!!
	double a_ERRORTHRESHOLD; // if the sum of errors in a single epoch is below this threshold keep training (in automatic training!!!)
	// outlets
	void **a_outlets; // as many as there are inputs, and one extra for the output list, and one extra for the info, and one for the end of iteration bang, and end of epoch bang
	long a_in; // the inlet index
	void *a_proxy; // the inlet proxy (so we can check who get's the bang)
	// dynamic (state) data
	long a_size; // the total number of training examples (size of the training set)
	long a_left; // number of examples left to process in the current iteration
	long a_iterationindex; // the current iteration
	long a_epochindex; // the epoch index (keeps track of the epoch)
	// I suppose we could use a forward linked list for storing the samples???? so every element has two pointers, one to the next set element, one to the
	// list of doubles, we still need a list of pointers for that (which we will allocated for every new list presented)
	t_anntrainingsetexample *a_firstexampleptr; // pointer to the first training example (= a pointer to two pointers)
	t_anntrainingsetexample *a_lastexampleptr; // the pointer to the next set element to output when banged (the outputs out the second outlet, the inputs out the first outlet)
	// we need to remember where we are in the set during training
	long a_exampleindex; // the current index in the epoch
	t_anntrainingsetexample *a_exampleptr; // the pointer to the next set element to output when banged (the outputs out the second outlet, the inputs out the first outlet)
} t_anntrainingset;
//* STRUCTURE END
//* PROTOTYPES Auto-generated by Max External Definition Editor
static t_class *anntrainingset_class;

/////void *anntrainingset_new(t_symbol *FUNCTION, long N, double MINWEIGHT, double MAXWEIGHT, double BIAS, double DUMMY);
void *anntrainingset_new(t_symbol *msg, long argc, t_atom *args);
void anntrainingset_free(t_anntrainingset *x);
void anntrainingset_reset(t_anntrainingset *x);

//* PROTOTYPES END
//* UTILITY FUNCTIONS Auto-generated by Max External Definition Editor
void anntrainingset_output_list(t_anntrainingset *x, short outlet_index, short argc, t_atom *argv) {
	if (outlet_index>=0&&outlet_index<x->a_INPUTS+2)
		outlet_list(x->a_outlets[outlet_index],0L,argc,argv);
	else
		object_error((t_object *)x,"MdH >> Index (%ld) of outlet to output list invalid.",outlet_index);
}
void anntrainingset_output_anything(t_anntrainingset *x, short outlet_index, t_symbol *msg, short argc, t_atom *argv) {
	if (outlet_index>=0&&outlet_index<x->a_INPUTS+2)
		outlet_anything(x->a_outlets[outlet_index],msg,argc,argv);
	else
		object_error((t_object *)x,"MdH >> Index (%ld) of outlet to output a message invalid.",outlet_index);
}
//* UTILITY FUNCTIONS END
//* STANDARD MESSAGE HANDLERS Auto-generated by Max External Definition Editor
void anntrainingset_respond_to_info(t_anntrainingset *x, void *parent, void *container) {
	//* @TODO insert your code to handle the Max GetInfo() message here
	//* @TODO END
}
void anntrainingset_respond_to_preset(t_anntrainingset *x) {
	//* @TODO insert your code to handle the preset message here
	//* @TODO END
}
void anntrainingset_respond_to_loadbang(t_anntrainingset *x) {
}
void anntrainingset_respond_to_assist(t_anntrainingset *x, void *box, long msg, long arg, char *dst) {
	// inlet/outlet assistance automatically generated based on the inlet/outlet info texts
	if (msg==ASSIST_INLET) { // request for information about an inlet
		switch (arg) {
			case 0:
				strcpy(dst,"bang to output a single example");
				break;
			case 1:
				strcpy(dst,"the batch size (number of examples used in a single iteration)");
				break;
			case 2:
				strcpy(dst,"bang to reset, or a list representing a single example to add");
				break;
		}
	} else
		if (msg==ASSIST_OUTLET) { // request for information about an outlet
			if (arg<x->a_INPUTS)
				sprintf(dst,"input value #%ld of the current example",(arg+1));
			else
				if (arg==x->a_INPUTS)
					strcpy(dst,"the list of expected output values of the current training example");
				else
					strcpy(dst,"training state variables (SIZE=size, BATCHSIZE=batch size, EPOCH=epoch counter, ITERATION=iteration counter, EXAMPLE=example index, LEFT=left in iteration index).");
		}
}
void anntrainingset_respond_to_save(t_anntrainingset *x, void *dest) {
}
//* STANDARD MESSAGE HANDLERS END
void anntrainingset_output_size(t_anntrainingset *x) {
	t_atom sizeatoms[1]; atom_setlong(sizeatoms,x->a_size); anntrainingset_output_anything(x,x->a_INPUTS+1,gensym("SIZE"),1,sizeatoms);
}
void anntrainingset_output_batchsize(t_anntrainingset *x) {
	t_atom batchsizeatoms[1]; atom_setlong(batchsizeatoms,x->a_BATCHSIZE); anntrainingset_output_anything(x,x->a_INPUTS+1,gensym("BATCHSIZE"),1,batchsizeatoms);
}
void anntrainingset_output_left(t_anntrainingset *x) {
	t_atom leftatoms[1]; atom_setlong(leftatoms,x->a_left); anntrainingset_output_anything(x,x->a_INPUTS+1,gensym("LEFT"),1,leftatoms);
}
void anntrainingset_output_iterationindex(t_anntrainingset *x) {
	t_atom iterationindexatoms[1]; atom_setlong(iterationindexatoms,x->a_iterationindex); anntrainingset_output_anything(x,x->a_INPUTS+1,gensym("ITERATION"),1,iterationindexatoms);
}
void anntrainingset_output_epochindex(t_anntrainingset *x) {
	t_atom epochindexatoms[1]; atom_setlong(epochindexatoms,x->a_epochindex); anntrainingset_output_anything(x,x->a_INPUTS+1,gensym("EPOCH"),1,epochindexatoms);
}
void anntrainingset_output_exampleindex(t_anntrainingset *x) {
	t_atom exampleindexatoms[1]; atom_setlong(exampleindexatoms,x->a_exampleindex); anntrainingset_output_anything(x,x->a_INPUTS+1,gensym("EXAMPLE"),1,exampleindexatoms);
}
void anntrainingset_resettraining(t_anntrainingset *x) {
	// NOTE that x->a_BATCHSIZE should be a divisor of the size, which is a problem because we're using a parameter to set the batch size
	//      I'm wondering whether we couldn't use the batch size as input to the entire training i.e. to signify starting the training
	//      in which case we do NOT use a bang to send out the next sample!!!
	x->a_left=0; // we have to do this so that when banging the first inlet (to output the example), the iteration will end, and a new iteration is started!!!
	x->a_iterationindex=0;
	x->a_epochindex=0;
	x->a_exampleindex=0;
	// I guess we could output these (except the left, only the things that are set to 0 meaning a reset basically of the training)
	// perhaps the EPOCH suffices
	anntrainingset_output_epochindex(x);
	anntrainingset_output_exampleindex(x);
	anntrainingset_output_iterationindex(x);
	anntrainingset_output_left(x);
}
//* INLET MESSAGE HANDLERS Auto-generated by Max External Definition Editor
void anntrainingset_respond_to_bang(t_anntrainingset *x) {
	int inlet_index=proxy_getinlet((t_object*)x);
	if (inlet_index==0) {
		// we are to output the next example and possibly a bang when the epoch is done!!!!!
		// NOTE if x->BATCHSIZE is not positive, we should output a train bang, or better, the train message out the last outlet!!!
		//      the bang should go into the error accumulator, so that it knows that it has to pass the errors into the output layer neurons
		if (x->a_size) {
			// NOTE initially x->a_exampleindex will be 0, so that we can do the following first
			if (!x->a_exampleptr) x->a_exampleindex=0; // this is safer than using x->a_exampleindex<=x->a_size
			bool startofepoch=(x->a_exampleindex<=0); // determine end of epoch based on whether the example index is 0 (in which case it is)
			x->a_exampleindex++; // increment the example index
			anntrainingset_output_exampleindex(x); // replacing: post("MdH >> Example #%ld to output.",x->a_exampleindex);
			
			if (startofepoch) {
				post("MdH >> End of epoch determined!");
				x->a_exampleptr=x->a_firstexampleptr; /////////post("MdH >> Example pointer initialized.");
				x->a_epochindex++; anntrainingset_output_epochindex(x); // increment the epoch index
			}
			
			// determine whether or not to increment the iteration counter
			if (x->a_left<=0) { // just behind the end of an iteration so apparently this is the start of an iteration
				x->a_iterationindex++; anntrainingset_output_iterationindex(x);
			}
			
			// update the number of examples left to output in this iteration (0 means end of the current iteration)
			x->a_left=x->a_BATCHSIZE-1-((x->a_exampleindex-1)%x->a_BATCHSIZE); anntrainingset_output_left(x); // will output 0 when this is the last example in the iteration!!!
			
			// ready to output the outputs and the inputs
			if (x->a_exampleptr->outputs) {
				// collect outputs
				int o=x->a_OUTPUTS; t_atom outputatoms[o]; while (--o>=0) atom_setfloat(outputatoms+o,x->a_exampleptr->outputs[o]);
				anntrainingset_output_list(x,x->a_INPUTS,x->a_OUTPUTS,outputatoms); // output outputs
				post("MdH >> Outputs output.");
			} else
				object_error((t_object*)x,"No outputs to output.");
			/*
			 // collect inputs
			 t_atom inputatoms[x->a_INPUTS];
			 int i=x->a_INPUTS; while (--i>=0) atom_setfloat(inputatoms+i,x->a_exampleptr->inputs[i]);
			 anntrainingset_output_list(x,0,x->a_INPUTS,inputatoms); // output inputs
			 */
			if (x->a_exampleptr->inputs) {
				int i=x->a_INPUTS; while (--i>=0) if (!outlet_float(x->a_outlets[i],x->a_exampleptr->inputs[i])) break;
				if (i>=0) object_error((t_object*)x,"Not all inputs output.");
			} else
				object_error((t_object *)x,"No inputs to output!");
			
			x->a_exampleptr=x->a_exampleptr->next; // go to the next example even on failure!!!
			post("MdH >> Ready.");
		} else
			object_error((t_object *)x,"No training examples (yet) available.");
	} else
		anntrainingset_resettraining(x);
}
// MDH@04NOV2015: we only need either a list of new weights, or a bang to output the weights (so there's no mode anymore!!!)
/*
 void anntrainingset_respond_to_anything(t_anntrainingset *x, t_symbol *msg, long argc, t_atom *args) {
 }
 */
/*
 void anntrainingset_newiteration(t_anntrainingset *x) {
	x->a_left=x->a_BATCHSIZE; // initialize the number of examples left to output in the iteration
	x->a_iterationindex++; // increment the iteration counter
	// a new iteration might start a new epoch???
	anntrainingset_output_left(x);
	anntrainingset_output_iterationindex(x);
 }
 */
// MDH@12MAY2017: training needs to be reset whenever an example is added to the training set so that we could start training immediately
void anntrainingset_respond_to_list(t_anntrainingset *x, t_symbol *msg, long argc, t_atom *args) {
	int inlet_index=proxy_getinlet((t_object*)x);
	if (inlet_index!=1) { // only the middle inlet is not used for entering an example
		if (argc>=x->a_INPUTS+x->a_OUTPUTS) { // at least x->a_N weights required!!!!
			// compute the weighted sum of the first x->a_N input values (don't forget the BIAS as initial value for x->sum!!!)
			argc=x->a_INPUTS+x->a_OUTPUTS; // we do NOT want to use additional input values (and overwrite the fixed bias value!!!)
			// I guess that when we start we might've created a new instance already???? and we need a pointer to the last instance
			// get a new anntrainingsetexample instance
			t_anntrainingsetexample *exampleptr=sysmem_newptr(sizeof(t_anntrainingsetexample));
			exampleptr->next=NULL; // I guess we need to do this!!!
			// if there's NO last example ptr yet (and therefore no first as well), we set the first example ptr
			// if there is a last example ptr we make the last example point to the new example
			// NOTE it's easier to test the SIZE!!!
			if (x->a_size) x->a_lastexampleptr->next=exampleptr; else x->a_firstexampleptr=exampleptr;
			x->a_lastexampleptr=exampleptr; // make the last example point to the new example
			// store the training example
			exampleptr->outputs=sysmem_newptr(x->a_OUTPUTS*sizeof(double));
			while (--argc>=x->a_INPUTS) {
				exampleptr->outputs[argc-x->a_INPUTS]=atom_getfloat(args+argc);
				post("MdH >> Output value #%ld of example #%ld: %f.",argc-x->a_INPUTS,x->a_size,exampleptr->outputs[argc-x->a_INPUTS]);
			}
			// remember the input, consuming argc in the process!!
			exampleptr->inputs=sysmem_newptr(x->a_INPUTS*sizeof(double));
			while (argc>=0) { exampleptr->inputs[argc]=atom_getfloat(args+argc); post("MdH >> Input value #%ld of example #%ld: %f.",argc,x->a_size,exampleptr->inputs[argc]); argc--; } // remember the input, consuming argc in the process!!
			// update and output the size of the training set
			x->a_size++; anntrainingset_output_size(x);
			// adapt the batchsize to match the number of examples
			x->a_BATCHSIZE=x->a_size; anntrainingset_output_batchsize(x);
			// reset the training so that a training could start immediately!!!
			anntrainingset_resettraining(x);
		} else
			object_error((t_object *)x,"The number of input values (%ld) should be at least %ld (the sum of the number of inputs and outputs).",argc,x->a_INPUTS+x->a_OUTPUTS);
	} else
		object_error((t_object *)x,"No example (list of inputs and outputs) accepted in the middle inlet.");
}
void anntrainingset_respond_to_int(t_anntrainingset *x, long n) {
	if (x->a_size==0) {
		object_error((t_object*)x,"The batch size can only be set after examples have been presented (in the right-most inlet)!");
	}
	if (n<1||n>x->a_size) {
		object_error((t_object*)x,"The batch size should be a positive value at most equal to the number of examples (%ld).",x->a_size);
		return;
	}
	if (x->a_size%n) {
		object_error((t_object*)x,"The batch size is not a divisor of the number of examples (%ld).",x->a_size);
		return;
	}
	x->a_BATCHSIZE=n;
	anntrainingset_output_batchsize(x);
}
void ext_main(void *r) {
	// START setup
	t_class *c;
	c=class_new("anntrainingset",(method)anntrainingset_new,(method)anntrainingset_free,(short)sizeof(t_anntrainingset),NIL,A_GIMME,A_NOTHING); // allocates class memory and sets up class
	// END setup
	
	// START message handler registration
	// standard message handlers
	class_addmethod(c,(method)anntrainingset_respond_to_assist,"assist",A_CANT,A_NOTHING);          // binding to assist message handler
	class_addmethod(c,(method)anntrainingset_respond_to_info,"info",A_CANT,A_NOTHING);          // binding to info message handler
	class_addmethod(c,(method)anntrainingset_respond_to_loadbang,"loadbang",A_CANT,A_NOTHING);          // binding to loadbang message handler
	class_addmethod(c,(method)anntrainingset_respond_to_preset,"preset",A_CANT,A_NOTHING);          // binding to preset message handler
	class_addmethod(c,(method)anntrainingset_respond_to_save,"save",A_CANT,A_NOTHING);          // binding to save message handler
	// specific message handlers
	class_addmethod(c,(method)anntrainingset_respond_to_bang,"bang",A_NOTHING);
	class_addmethod(c,(method)anntrainingset_respond_to_list,"list",A_GIMME,A_NOTHING);
	
	class_addmethod(c, (method)anntrainingset_respond_to_int,"in1",A_LONG,A_NOTHING);
	
	finder_addclass("MDH_ANN","anntrainingset"); // the category to put the object into
	
	class_register(CLASS_BOX,c); // add this class to the CLASS_BOX namespace
	
	anntrainingset_class=c; // reference to class instance
}
//* MAIN END
// freeing the examples is interesting
void anntrainingset_free_examples(t_anntrainingset *x) {
	t_anntrainingsetexample *nextexampleptr;
	t_anntrainingsetexample *exampleptr=x->a_firstexampleptr;
	while (exampleptr) {
		nextexampleptr=exampleptr->next; // remember whatever the example points to
		sysmem_freeptr(exampleptr->inputs); // release inputs memory
		sysmem_freeptr(exampleptr->outputs); // release outputs memory
		sysmem_freeptr(exampleptr); // release example memory
		exampleptr=nextexampleptr; // process the next example
	}
}
void anntrainingset_initialize(t_anntrainingset *x) {
	// NOTE leave the arguments alone, but initialize the rest
	x->a_firstexampleptr=NULL;
	x->a_lastexampleptr=NULL;
	x->a_exampleptr=NULL;
	x->a_size=0;
	// let's output the size at least!!!
	anntrainingset_output_size(x);
}
// resetting means free all memory to dynamically allocated things!!!
void anntrainingset_reset(t_anntrainingset *x) {
	anntrainingset_free_examples(x);
	anntrainingset_initialize(x);
	anntrainingset_resettraining(x);
}
//* NEW Auto-generated by Max External Definition Editor
/////////void *an_new(t_symbol *FUNCTION, long N, long M, double BIAS) {
//////void *an_new(t_symbol *FUNCTION, long N, double MINWEIGHT, double MAXWEIGHT, double BIAS, double DUMMY) {
// MDH@12MAY2017: the length of an epoch always is the total number of examples in the training set
//                so I've renamed BATCHSIZE to BATCHSIZE which is the number of examples to use in one iteration
//                an iteration means passing in BATCHSIZE examples (1<=BATCHSIZE<=EPOCH) and training afterwards
//                NOTE we'd let the anntrainingset to output a bang on the end of an iteration and on the end of the epoch
void *anntrainingset_new(t_symbol *msg, long argc,t_atom *args) {
	t_anntrainingset *x; // the object to create and to be returned
	// allocate space for an instance of your class and initialize the object header
	x=(t_anntrainingset *)object_alloc(anntrainingset_class);
	// initialize arguments
	x->a_INPUTS=1;
	x->a_OUTPUTS=1; // default: 1 input and 1 output
	x->a_BATCHSIZE=0; // default: the entire training set constitutes a single iteration
	x->a_ERRORTHRESHOLD=0.0; // default: no limitations on the iteration error
	x->a_ITERATIONS=0; // default: no limitations on the maximum number of iterations
	// extract arguments
	if (argc>0) {
		x->a_INPUTS=atom_getlong(args);
		if (argc>1) {
			x->a_OUTPUTS=atom_getlong(args+1);
			if (argc>2) {
				x->a_BATCHSIZE=atom_getlong(args+2);
				if (argc>3) {
					x->a_ERRORTHRESHOLD=atom_getfloat(args+3);
					if (argc>4) x->a_ITERATIONS=atom_getlong(args+4);
				}
			}
		}
	}
	post("MdH >> anntrainingset parameters: inputs=%ld,outputs=%ld,[error threshold=%f,[maximum iterations=%ld]].",x->a_INPUTS,x->a_OUTPUTS,x->a_BATCHSIZE,x->a_ERRORTHRESHOLD,x->a_ITERATIONS);
	// create the proxy for the second inlet (apparently one for each additional inlet)
	x->a_proxy=proxy_new(x,2,&x->a_in); // i.e. the third inlet is a proxy inlet!!!
	intin(x,1); // expecting the batch size in the second inlet
	
	// NOTE we might consider having a_INPUTS outlets outputting a single float, whereas the outputs go out a single outlet
	// START creation of outlets
	x->a_outlets=sysmem_newptr((x->a_INPUTS+2)*sizeof(void*));
	x->a_outlets[x->a_INPUTS+1]=outlet_new(x,NULL); // we'd like a message outlet (e.g. to report parameters!!!)
	x->a_outlets[x->a_INPUTS]=listout(x); // will output the expected outputs there!!
	int i=x->a_INPUTS; while (--i>=0) x->a_outlets[i]=floatout(x); // the outlets for sending out the example input values (from right to left)
	// END creation of outlets
	
	anntrainingset_initialize(x);
	
	//* TODO END
	return (x);
}
//* NEW END
void anntrainingset_free(t_anntrainingset *x) {
	anntrainingset_free_examples(x);
	sysmem_freeptr(x->a_outlets); // free the outlets
	sysmem_freeptr(x->a_proxy); // free the proxy inlet
}
